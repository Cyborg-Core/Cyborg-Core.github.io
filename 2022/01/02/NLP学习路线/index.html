<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="pragma" content="no-cache">
  <meta http-equiv="cache-control" content="no-cache">
  <meta http-equiv="expires" content="0">
  
  <title>Cyborg Core</title>
  <meta name="author" content="Nash Liu">
  
  <meta name="description" content="课程大纲第一部分：机器学习基础篇
第一章：自然语言处理概述

自然语言处理的现状与前景
自然语言处理应用
自然语言处理经典任务

第二章：数据结构与算法基础

时间复杂度、空间复杂度
动态规划
贪心算法
各种排序算法

第三章：分类与逻辑回归

逻辑回归
最大似然估计

优化与梯度下降法

随机梯度下降法

第四章：模型泛化与调参

理解过拟合、防止过拟合

L1与L2正则

交叉验证

正则与MAP估计"> 
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Cyborg Core"/>

  
    <meta property="og:image" content=""/>
  

  
  
    <link href="/favicon.png" rel="icon">
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>

  <!-- analytics -->
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-70812759-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-70812759-1');
</script>






<meta name="generator" content="Hexo 6.0.0"></head>

 <body>  
  <nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/">Cyborg Core</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class=""></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class=""></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/tags" title="All the tags.">
			  <i class=""></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class=""></i>About
			</a>
		  </li>
		  
		  <li>
			<a href="/atom.xml" title="Subscribe me.">
			  <i class=""></i>RSS
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 


	
		<div class="page-header">
			<h1> </h1>
		</div>
	



<div class="row post">
	<!-- cols -->
	
	<div id="top_meta"></div>
	<div class="col-md-9">
	

	<!-- content -->
	<div class="mypage">		
	  		

	  <h1 id="课程大纲"><a href="#课程大纲" class="headerlink" title="课程大纲"></a>课程大纲</h1><p><strong>第一部分：机器学习基础篇</strong></p>
<p><strong>第一章：自然语言处理概述</strong></p>
<ul>
<li>自然语言处理的现状与前景</li>
<li>自然语言处理应用</li>
<li>自然语言处理经典任务</li>
</ul>
<p><strong>第二章：数据结构与算法基础</strong></p>
<ul>
<li>时间复杂度、空间复杂度</li>
<li>动态规划</li>
<li>贪心算法</li>
<li>各种排序算法</li>
</ul>
<p><strong>第三章：分类与逻辑回归</strong></p>
<ul>
<li>逻辑回归</li>
<li><p>最大似然估计</p>
</li>
<li><p>优化与梯度下降法</p>
</li>
<li>随机梯度下降法</li>
</ul>
<p><strong>第四章：模型泛化与调参</strong></p>
<ul>
<li><p>理解过拟合、防止过拟合</p>
</li>
<li><p>L1与L2正则</p>
</li>
<li><p>交叉验证</p>
</li>
<li><p>正则与MAP估计</p>
</li>
</ul>
<p><strong>第二部分：文本处理篇</strong></p>
<p><strong>第五章：文本预处理与表示</strong></p>
<ul>
<li><p>各类分词算法</p>
</li>
<li><p>词的标准化</p>
</li>
<li><p>拼写纠错、停用词</p>
</li>
<li><p>独热编码表示</p>
</li>
<li><p>tf-idf与相似度</p>
</li>
<li><p>分布式表示与词向量</p>
</li>
<li><p>词向量可视化与评估</p>
</li>
</ul>
<p><strong>第六章：词向量技术</strong></p>
<ul>
<li>独热编码的优缺点</li>
<li>分布式表示的优点</li>
<li>静态词向量与动态词向量</li>
<li>SkipGram与CBOW</li>
<li>SkipGram详解</li>
<li>Negative Sampling</li>
</ul>
<p><strong>第七章：语言模型</strong></p>
<ul>
<li>语言模型的作用</li>
<li>马尔科夫假设</li>
<li>UniGram, BiGram, NGram模型</li>
<li>语言模型的评估</li>
<li>语言模型的平滑技术</li>
</ul>
<p><strong>第三部分：序列模型篇</strong></p>
<p><strong>第八章：隐马尔科夫模型</strong></p>
<ul>
<li><p>HMM的应用</p>
</li>
<li><p>HMM的Inference</p>
</li>
<li><p>维特比算法</p>
</li>
<li><p>前向、后向算法</p>
</li>
<li><p>HMM的参数估计详解</p>
</li>
</ul>
<p><strong>第九章：线性条件随机场</strong></p>
<ul>
<li>有向图与无向图</li>
<li>生成模型与判别模型</li>
<li>从HMM与MEMM</li>
<li>MEMM中的标签偏置</li>
<li>Log-Linear模型介绍</li>
<li>从Log-Linear到LinearCRF</li>
<li>LinearCRF的参数估计</li>
</ul>
<p><strong>第四部分：深度学习与预训练篇</strong></p>
<p><strong>第十章：深度学习基础</strong></p>
<ul>
<li>理解神经网络</li>
<li>各种常见的激活函数</li>
<li>反向传播算法</li>
<li>浅层模型与深度模型对比</li>
<li>深度学习中的层次表示</li>
<li>深度学习中的过拟合</li>
</ul>
<p><strong>第十一章：RNN与LSTM</strong></p>
<ul>
<li>从HMM到RNN模型</li>
<li>RNN中的梯度问题</li>
<li>梯度消失与LSTM</li>
<li>LSTM到GRU</li>
<li>双向LSTM</li>
<li>双向深度LSTM</li>
</ul>
<p><strong>第十二章：Seq2Seq模型与注意力机制</strong></p>
<ul>
<li>Seq2Seq模型</li>
<li>Greedy Decoding</li>
<li>Beam Search</li>
<li>长依赖所存在的问题</li>
<li>注意力机制的实现</li>
</ul>
<p><strong>第十三章：动态词向量与ELMo技术</strong></p>
<ul>
<li>基于上下文的词向量技术</li>
<li>图像识别中的层次表示</li>
<li>文本领域中的层次表示</li>
<li>ELMo模型</li>
<li>ELMo的预训练与测试</li>
<li>ELMo的优缺点</li>
</ul>
<p><strong>第十四章：自注意力机制与Transformer</strong></p>
<ul>
<li>LSTM模型的缺点</li>
<li>Transformer概述</li>
<li>理解自注意力机制</li>
<li>位置信息的编码</li>
<li>理解Encoder和Decoder区别</li>
<li>理解Transformer的训练与预测</li>
<li>Transformer的缺点</li>
</ul>
<p><strong>第十五章：BERT与ALBERT</strong></p>
<ul>
<li><p>自编码介绍</p>
</li>
<li><p>Transformer Encoder</p>
</li>
<li><p>Masked语言模型</p>
</li>
<li><p>BERT模型</p>
</li>
<li><p>BERT的不同训练方式</p>
</li>
<li><p>ALBERT </p>
</li>
</ul>
<p><strong>第十六章：BERT的其他变种</strong></p>
<ul>
<li>RoBERTa模型</li>
<li>SpanBERT模型</li>
<li>FinBERT模型</li>
<li>引入先验知识</li>
<li>K-BERT</li>
<li>KG-BERT</li>
</ul>
<p><strong>第十七章：GPT与XLNet</strong></p>
<ul>
<li><p>Transformer Encoder回顾</p>
</li>
<li><p>GPT-1, GPT-2, GPT-3</p>
</li>
<li><p>ELMo的缺点</p>
</li>
<li><p>语言模型下同时考虑上下文</p>
</li>
<li><p>Permutation LM</p>
</li>
<li><p>双流自注意力机制</p>
</li>
</ul>
<p><strong>第五部分：信息抽取与知识图谱篇</strong></p>
<p><strong>第十八章：命名识别与实体消歧</strong></p>
<ul>
<li>信息抽取的应用和关键技术</li>
<li>命名实体识别</li>
<li>NER识别常用技术</li>
<li>实体统一技术</li>
<li>实体消歧技术</li>
<li>指代消解</li>
</ul>
<p><strong>第十九章：关系抽取</strong></p>
<ul>
<li>关系抽取的应用</li>
<li>基于规则的方法</li>
<li>基于监督学习的方法</li>
<li>Bootstrap方法</li>
<li>Distant Supervision方法</li>
</ul>
<p><strong>第二十章：句法分析</strong></p>
<ul>
<li>句法分析的应用</li>
<li>CFG介绍</li>
<li>从CFG到PCFG</li>
<li>评估语法树</li>
<li>寻找最好的语法树</li>
<li>CKY算法</li>
</ul>
<p><strong>第二十一章：依存文法分析</strong></p>
<ul>
<li>从语法分析到依存文法分析</li>
<li>依存文法分析的应用</li>
<li>基于图算法的依存文法分析</li>
<li>基于Transition-based的依存文法分析</li>
<li>依存文法的应用案例</li>
</ul>
<p><strong>第二十二章：知识图谱</strong></p>
<ul>
<li>知识图谱的重要性</li>
<li>知识图谱中的实体与关系</li>
<li>非结构化数据与构造知识图谱</li>
<li>知识图谱设计</li>
<li>图算法的应用</li>
</ul>
<p><strong>第六部分：模型压缩与图神经网络篇</strong></p>
<p><strong>第二十三章：模型的压缩</strong></p>
<ul>
<li>模型压缩重要性</li>
<li>常见的模型压缩总览</li>
<li>基于矩阵分解的压缩技术</li>
<li>基于蒸馏的压缩技术</li>
<li>基于贝叶斯模型的压缩技术</li>
<li>模型的量化</li>
</ul>
<p><strong>第二十四章：基于图的学习</strong></p>
<ul>
<li>图的表示</li>
<li>图与知识图谱</li>
<li>关于图的常见算法</li>
<li>Deepwalk和Node2vec</li>
<li>TransE图嵌入算法</li>
<li>DSNE图嵌入算法</li>
</ul>
<p><strong>第二十五章：图神经网络</strong></p>
<ul>
<li>卷积神经网络回顾</li>
<li>在图中设计卷积操作</li>
<li>图中的信息传递</li>
<li>图卷积神经网络</li>
<li>图卷积神经网络的经典应用</li>
</ul>
<p><strong>第二十六章：GraphSage与GAT</strong></p>
<ul>
<li>从GCN到GraphSAge</li>
<li>注意力机制回归</li>
<li>GAT模型详解</li>
<li>GAT与GCN比较</li>
<li>对于异构数据的处理</li>
</ul>
<p><strong>第二十七章：图神经网络的其他应用</strong></p>
<ul>
<li>Node Classification</li>
<li>Graph Classification</li>
<li>Link Prediction</li>
<li>社区挖掘</li>
<li>推荐系统</li>
<li>图神经网络的未来发展</li>
</ul>
<p><strong>02 课程中的部分案例</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>1. 实现一个拼写纠错器</th>
</tr>
</thead>
<tbody>
<tr>
<td>2. 从零实现Word2Vec词向量</td>
</tr>
<tr>
<td>3. 利用SkipGram做推荐</td>
</tr>
<tr>
<td>4. 从零实现HMM模型</td>
</tr>
<tr>
<td>5. 基于Linear-CRF的词性分类器实现</td>
</tr>
<tr>
<td>6. 从零实现深度学习反向传播算法</td>
</tr>
<tr>
<td>7. 实现AI程序帮助写程序</td>
</tr>
<tr>
<td>8. 实现AI程序帮助写文章</td>
</tr>
<tr>
<td>9. 基于Transformer的机器翻译</td>
</tr>
<tr>
<td>10. 基于KG-BERT的知识图谱学习</td>
</tr>
<tr>
<td>11. 基于知识图谱的风控系统</td>
</tr>
<tr>
<td>12. 基于知识图谱的个性化教学</td>
</tr>
<tr>
<td>13. 利用蒸馏算法压缩Transformer</td>
</tr>
<tr>
<td>14. 利用GCN实现社交推荐</td>
</tr>
<tr>
<td>15. 基于GAT的虚假新闻检测</td>
</tr>
<tr>
<td><strong>（剩下20+个案例被折叠，完整请咨询…）</strong></td>
</tr>
</tbody>
</table>
</div>
<p><strong>03 课程中的部分项目作业</strong></p>
<p>​    </p>
<p><strong>1. 豆瓣电影评分预测</strong></p>
<p>  涉及到的知识点：</p>
<ul>
<li>中文分词技术</li>
<li>独热编码、tf-idf</li>
<li>分布式表示与Word2Vec</li>
<li>BERT向量、句子向量</li>
</ul>
<p><strong>2. 智能客服问答系统</strong></p>
<p>  涉及到的知识点<strong>：</strong></p>
<ul>
<li>问答系统搭建流程</li>
<li>文本的向量化表示</li>
<li>FastText</li>
<li>倒排表</li>
<li>问答系统中的召回、排序</li>
</ul>
<p><strong>3. 基于Linear-CRF的医疗实体识别</strong></p>
<p>  涉及到的知识点<strong>：</strong></p>
<ul>
<li>命名实体识别</li>
<li>特征工程</li>
<li>评估标准</li>
<li>过拟合</li>
</ul>
<p><strong>4. 基于闲聊的对话系统搭建</strong></p>
<p>  涉及到的知识点<strong>：</strong></p>
<ul>
<li>常见的对话系统技术</li>
<li>闲聊型对话系统框架</li>
<li>数据的处理技术</li>
<li>BERT的使用</li>
<li>Transformer的使用</li>
</ul>
<p><strong>5. 搭建基于医疗知识图谱的问答系统</strong></p>
<p>  涉及到的知识点<strong>：</strong></p>
<ul>
<li>医疗专业词汇的使用</li>
<li>获取问句的意图</li>
<li>问句的解释、提取关键实体</li>
<li>转化为查询语句</li>
</ul>
<p><strong>6. 搭建基于医疗知识图谱的问答系统</strong></p>
<p>  涉及到的知识点<strong>：</strong></p>
<ul>
<li>文本摘要生成介绍</li>
<li>关键词提取技术</li>
<li>图神经网络的摘要生成</li>
<li>基于生成式的摘要提取技术</li>
<li>文本摘要质量的评估</li>
</ul>
<p><strong>04 课程中带读的部分论文</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>主题</th>
<th>论文名称</th>
</tr>
</thead>
<tbody>
<tr>
<td>机器学习</td>
<td>XGBoost: A Scalable Tree Boosting System</td>
</tr>
<tr>
<td>机器学习</td>
<td>Regularization and Variable Selection via the Elastic Net</td>
</tr>
<tr>
<td>词向量</td>
<td>Evaluation methods for unsupervised word embeddings</td>
</tr>
<tr>
<td>词向量</td>
<td>Evaluation methods for unsupervised word embeddings</td>
</tr>
<tr>
<td>词向量</td>
<td>GloVe: Global Vectors for Word Representation</td>
</tr>
<tr>
<td>词向量</td>
<td>Deep Contexualized Word Representations</td>
</tr>
<tr>
<td>词向量</td>
<td>Attention is All You Need</td>
</tr>
<tr>
<td>词向量</td>
<td>BERT: Pretraining of Deep Bidirectional Transformers for Language Understanding</td>
</tr>
<tr>
<td>词向量</td>
<td>XLNet: Generalized Autoregressive Pretraining for Language Understanding</td>
</tr>
<tr>
<td>词向量</td>
<td>KG-BERT: BERT for Knowledge Graph Completion</td>
</tr>
<tr>
<td>词向量</td>
<td>Language Models are Few-shot Learners</td>
</tr>
<tr>
<td>图学习</td>
<td>Semi-supervised Classification with Graph Convolutional Networks</td>
</tr>
<tr>
<td>图学习</td>
<td>Graph Attention Networks</td>
</tr>
<tr>
<td>图学习</td>
<td>GraphSAGE: Inductive Representation Learning on Large Graphs</td>
</tr>
<tr>
<td>图学习</td>
<td>Node2Vec: Scalable Feature Learning for Networks</td>
</tr>
<tr>
<td><strong>被折叠 </strong></td>
<td><strong>其他数十篇文章…… </strong></td>
</tr>
</tbody>
</table>
</div>

	  <div class="article-footer-copyright">

    本博客采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议(CC BY-NC-SA 4.0) 发布.</a>
</div>

	</div>

	
	<span id="/2022/01/02/NLP%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/" class="leancloud-visitors view" data-flag-title="">
		<em class="post-meta-item-text"> Page View </em> <i class="leancloud-visitors-count"></i>
	</span>
	
	<div>
  	<center>

	<div class="pagination">

    
    
    <a href="/2022/01/03/Java后端开发学习路线/" type="button" class="btn btn-default"><i
                class="fa fa-arrow-circle-o-left"></i> Prev</a>
    

    <a href="/" type="button" class="btn btn-default"><i class="fa fa-home"></i>Home</a>
    
    <a href="/2022/01/02/test_folder/test/" type="button" class="btn btn-default ">Next<i
                class="fa fa-arrow-circle-o-right"></i></a>
    

    
</div>


    </center>
	</div>
	
	<!-- comment -->
	<!--
<section id="comment">
    <h2 class="title">Comments</h2>

    
</section>

-->
	
		<section id="comments" class="comments">
			<style>
			.comments{margin:30px;padding:10px;background:rgb(0, 0, 0)}
			@media screen and (max-width:800px){.comments{margin:auto;padding:10px;background:#000}}
			</style>
			<div id="vcomment" class="comment"></div>
<script src='//unpkg.com/valine/dist/Valine.min.js'></script>
<script src="https://cdnjs.loli.net/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
<script>
var valineConfig = {"enable":true,"appId":"xxx","appKey":"xxx","placeholder":"提交评论时留下邮箱收到回复后将自动通知","visitor":true,"avatar":"monsterid","requiredFields":["nick","mail"]}
valineConfig.el='#vcomment';
new Valine(valineConfig);
    // new Valine({
    //     el: '#vcomment',
    //     appId: "",
    //     appKey: "",
    //     placeholder: "提交评论时留下邮箱收到回复后将自动通知",
    //     avatar:"monsterid",
    //     visitor: "true",
    //     requiredFields: "nick,mail".split(','),
    // });
</script>

		</section>
	
	</div> <!-- col-md-9/col-md-12 -->


	
	<div id="side_meta">
		<div class="col-md-3" id="post_meta"> 

	<!-- date -->
	
	<div class="meta-widget">
	<i class="fa fa-clock-o"></i>
	2022-01-02 
	</div>
	

	<!-- categories -->
    

	<!-- tags -->
		

	<!-- toc -->
	<div class="meta-widget">
	
	</div>
	
    <hr>
	
</div><!-- col-md-3 -->

		

	</div>
	
		

</div><!-- row -->

<!--
 -->



	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  
  &copy; 2022 Nash Liu's Blog
  
      powered by <a href="http://hexo.io/" target="_blank">Hexo</a>.Theme <a href="https://github.com/Ares-X/hexo-theme-freemind.bithack" target="_blank">freemind.bithack</a>  
</p>
 </footer>
</div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>⬆︎TOP</span>
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
   </html>
